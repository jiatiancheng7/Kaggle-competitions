{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Imputer\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_train_ori = pd.read_csv('../input/train.csv', header=0)\ndata_test_ori = pd.read_csv('../input/test.csv', header=0)\n# data_train\ntest_price = pd.read_csv('../input/sample_submission.csv', header=0)\n# test_price\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# loss function\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_error(a,b,data):\n    totalError = 0\n    x = data[:,:-1]\n    y = data[:,-1]\n    s = np.sum(b*x,axis=1)\n    totalError = (y-a-s)**2   # 求离差    \n    totalError = np.sum(totalError,axis=0)   # 求所有离差的和\n    totalError = totalError/float(len(data))\n    print('Error:',totalError)\n    return totalError#/float(len(data))   # 求离差和的平均值\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compute gradient"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_gradient(a_current,b_current,data,learning_rate):  #函数compute_gradient 对当前的a,b进行一次梯度迭代运算\n    N = float(len(data)*10)\n    x = data[:,:-1]    \n    y = data[:,-1]\n    s = np.sum(b_current*x,axis=1)\n   \n  \n    a_gradient = -(2/N)*(y-s-a_current)\n    a_gradient = np.sum(a_gradient,axis=0)  \n    cost = (y-s-a_current).reshape(len(data),1)\n    b_gradient = -(2/N)*x*cost  #此处求出是正梯度\n    b_gradient = np.sum(b_gradient,axis=0)\n    \n    #a与b值的更新\n    new_a = a_current - (learning_rate * a_gradient)  #- (learning_rate * a_gradient) 负梯度\n    new_b = b_current - (learning_rate * b_gradient)\n        \n    return [new_a,new_b]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PreProcessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = data_train_ori[['MSSubClass','LotArea','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','SalePrice']]\nprint (data_train.isnull().sum())\ndata_train = data_train.values\n\ndata_test = data_test_ori[['MSSubClass','LotArea','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea']]\nprint(data_test)\n\n#使用SKLearn来填充缺失值\nmy_imputer = Imputer()\ndata_imputed = my_imputer.fit_transform(data_test)\ndf_data_imputed = pd.DataFrame(data_imputed,columns=data_test.columns)\n# print (df_data_imputed.isnull().sum())\n\ndata_test_y = test_price[['SalePrice']]\n\ndata_test = pd.concat((df_data_imputed, data_test_y), axis=1)\ndata_test = data_test.values\n# print(data_test)\n\n#使用SKLearn是数据标准化\nss = StandardScaler()\nss.fit(data_train)\nX_train_std = ss.transform(data_train)\nX_test_std = ss.transform(data_test)\n\ninitial_a = 0.0\ninitial_b = np.zeros((1,7))\n# print(initial_b)\nlearning_rate = 0.001\nnum_iter = 3000\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\na = initial_a\nb = initial_b\nfor i in range(num_iter):\n    a,b =compute_gradient(a,b,X_train_std,learning_rate)\n    print('iter {0}:In sample error={1}'.format(i,compute_error(a,b,X_train_std)))\n\n    \nprint('a = {0}; b = {1}'.format(a,b))\nprint('Out of sample error={0}'.format(compute_error(a,b,X_test_std)))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}